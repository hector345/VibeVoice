# Demo de Chat con LM Studio + VibeVoice

Este demo permite conversar con un modelo de lenguaje alojado en LM Studio y recibir las respuestas en audio usando VibeVoice para sÃ­ntesis de voz.

## ğŸš€ CaracterÃ­sticas

- **Chat interactivo**: Conversa por texto con cualquier modelo de LM Studio
- **Respuestas en audio**: Las respuestas se convierten automÃ¡ticamente a voz
- **MÃºltiples voces**: Elige entre diferentes voces y idiomas disponibles
- **Historial de conversaciÃ³n**: Mantiene contexto durante la conversaciÃ³n
- **Comandos especiales**: Control total sobre la experiencia de chat

## ğŸ“‹ Requisitos Previos

### 1. LM Studio
- Descargar e instalar [LM Studio](https://lmstudio.ai/)
- Cargar un modelo de lenguaje en LM Studio
- Iniciar el servidor local en `http://127.0.0.1:1234`

### 2. VibeVoice
- Modelo VibeVoice descargado (ej: `microsoft/VibeVoice`)
- Voces instaladas en `demo/voices/streaming_model/`

### 3. Dependencias Python
```bash
pip install requests torch transformers
# o instalar desde el archivo de requisitos:
pip install -r demo/requirements_chat.txt
```

## ğŸ¯ Uso RÃ¡pido

### Uso bÃ¡sico:
```bash
python demo/chat_with_lm_studio.py --model_path microsoft/VibeVoice
```

### Con configuraciÃ³n personalizada:
```bash
python demo/chat_with_lm_studio.py \
    --model_path microsoft/VibeVoice \
    --speaker_name Emma \
    --device cuda \
    --lm_studio_url http://127.0.0.1:1234
```

### Listar voces disponibles:
```bash
python demo/chat_with_lm_studio.py --list_voices
```

## ğŸ­ Voces Disponibles

El demo incluye soporte para mÃºltiples idiomas y gÃ©neros:

- **InglÃ©s**: Emma (mujer), Carter, Davis, Frank, Mike (hombres), Grace (mujer)
- **EspaÃ±ol**: Spk0 (mujer), Spk1 (hombre) 
- **FrancÃ©s**: Spk0 (hombre), Spk1 (mujer)
- **AlemÃ¡n**: Spk0 (hombre), Spk1 (mujer)
- **Italiano**: Spk0 (mujer), Spk1 (hombre)
- **PortuguÃ©s**: Spk0 (mujer), Spk1 (hombre)
- **JaponÃ©s**: Spk0 (hombre), Spk1 (mujer)
- **Coreano**: Spk0 (mujer), Spk1 (hombre)
- **HolandÃ©s**: Spk0 (hombre), Spk1 (mujer)
- **Polaco**: Spk0 (hombre), Spk1 (mujer)
- **Hindi**: Samuel (hombre)

## ğŸ’¬ Comandos de Chat

Durante el chat, puedes usar estos comandos especiales:

- `/help` - Mostrar ayuda
- `/voices` - Listar todas las voces disponibles
- `/voice <nombre>` - Cambiar la voz (ej: `/voice Emma`)
- `/clear` - Limpiar el historial de conversaciÃ³n
- `/quit` - Salir del chat

## ğŸ“ Archivos Generados

Los archivos de audio se guardan automÃ¡ticamente en:
```
./chat_outputs/chat_response_<timestamp>.wav
```

## âš™ï¸ ConfiguraciÃ³n de LM Studio

### 1. Instalar y configurar LM Studio:
```
1. Descargar LM Studio desde https://lmstudio.ai/
2. Instalar y abrir la aplicaciÃ³n
3. Descargar un modelo de lenguaje (ej: Llama, Mistral, etc.)
4. Ir a la pestaÃ±a "Local Server"
5. Seleccionar el modelo cargado
6. Iniciar el servidor en puerto 1234
```

### 2. Verificar que el servidor estÃ© funcionando:
Los logs de LM Studio deberÃ­an mostrar algo como:
```
[INFO] [LM STUDIO SERVER] Supported endpoints:
[INFO] [LM STUDIO SERVER] ->	GET  http://localhost:1234/v1/models
[INFO] [LM STUDIO SERVER] ->	POST http://localhost:1234/v1/chat/completions
[INFO] [LM STUDIO SERVER] ->	POST http://localhost:1234/v1/completions
```

### 3. Probar la conexiÃ³n:
```bash
curl http://127.0.0.1:1234/v1/models
```

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "No se pudo conectar con LM Studio"
- Verificar que LM Studio estÃ© ejecutÃ¡ndose
- Confirmar que el servidor estÃ© en `http://127.0.0.1:1234`
- Verificar que hay un modelo cargado en LM Studio

### Error: "Voz no encontrada"
- Usar `/voices` para ver las voces disponibles
- Verificar que los archivos `.pt` estÃ©n en `demo/voices/streaming_model/`
- Probar con una voz diferente como `Emma` o `Carter`

### Error: "Error al inicializar VibeVoice"
- Verificar que el modelo VibeVoice estÃ© descargado correctamente
- Comprobar la ruta del modelo con `--model_path`
- Verificar disponibilidad de GPU/CPU segÃºn `--device`

### Problemas de memoria/rendimiento
- Usar `--device cpu` si hay problemas con GPU
- Cerrar otras aplicaciones que usen mucha memoria
- Para modelos grandes, considerar usar cuantizaciÃ³n en LM Studio

## ğŸ“ Ejemplo de Uso

```bash
$ python demo/chat_with_lm_studio.py --model_path microsoft/VibeVoice --speaker_name Emma

ğŸ¤– VibeVoice + LM Studio Chat Demo
==================================================
âœ… Conectado a LM Studio. Modelos disponibles: llama-3.2-3b-instruct
âœ… VibeVoice inicializado correctamente
ğŸ­ Voz actual: Emma
ğŸ’¡ Comandos especiales:
  /help    - Mostrar ayuda
  /voices  - Listar voces disponibles
  /voice <nombre> - Cambiar voz
  /clear   - Limpiar historial
  /quit    - Salir
==================================================

ğŸ‘¤ TÃº: Hola, Â¿cÃ³mo estÃ¡s?

ğŸ¤” Pensando...
ğŸ¤– Asistente: Â¡Hola! Estoy muy bien, gracias por preguntar. Soy un asistente de inteligencia artificial y estoy aquÃ­ para ayudarte con lo que necesites. Â¿En quÃ© puedo asistirte hoy?

ğŸµ Generando audio...
ğŸ”Š Audio guardado en: ./chat_outputs/chat_response_1703123456.wav
âœ… Listo! Audio disponible en: ./chat_outputs/chat_response_1703123456.wav

ğŸ‘¤ TÃº: /voice Carter

âœ… Voz cambiada a: Carter

ğŸ‘¤ TÃº: CuÃ©ntame un chiste
```

## ğŸ”„ IntegraciÃ³n con Otros Servicios

Este demo puede adaptarse fÃ¡cilmente para trabajar con otros servicios de IA:

- **OpenAI API**: Cambiar el endpoint a `https://api.openai.com/v1/chat/completions`
- **Anthropic Claude**: Adaptar para usar la API de Anthropic
- **Ollama**: Usar `http://localhost:11434/v1/chat/completions`
- **Otros modelos locales**: Cualquier servicio compatible con OpenAI API

## ğŸ“„ Licencia

Este demo estÃ¡ incluido bajo la misma licencia que VibeVoice.